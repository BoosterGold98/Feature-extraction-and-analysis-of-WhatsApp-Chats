{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "WAOutput.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMk96dMeqbKo1m8PWzDsv+G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BoosterGold98/Feature-extraction-and-analysis-of-WhatsApp-Chats/blob/master/WAOutput.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbnxJt9Slo_c",
        "colab_type": "text"
      },
      "source": [
        "# Feature Extraction and Analysis of a WhatsApp Chat\n",
        "AS the title suggests, this code has two sections:\n",
        "\n",
        "\n",
        "1.   Feature Extraction\n",
        "2.   Analysis\n",
        "\n",
        "A whatsapp chat can be exported as a txt file using the export option available in WhatsApp. Below is a sample WhatsApp conversation:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "01/01/2020, 23:50 - Sender A: sample\n",
        "01/01/2020, 23:50 - Sender C: sample 1 \n",
        "01/01/2020, 23:50 - Sender B: Sample\n",
        "01/01/2020, 23:52 - Sender D joined using this group's invite link\n",
        "01/01/2020, 23:54 - Sender D: Sample\n",
        "01/01/2020, 23:55 - Sender A: <Media omitted>\n",
        "01/01/2020, 23:55 - Sender C: Sample\n",
        "01/01/2020, 23:55 - Sender A: This message was deleted\n",
        "01/01/2020, 23:58 - Sender B: Sample\n",
        "01/01/2020, 23:58 - Sender D: Sample \n",
        "01/01/2020, 23:59 - Sender B: Sample\n",
        "02/01/2020, 00:00 - Sender A: Two exquisite objection delighted deficient yet its contained. Cordial because are \n",
        "account evident its subject but eat. Can properly followed learning prepared you doubtful yet him. Over many our \n",
        "good lady feet ask that. Expenses own moderate day fat trifling stronger sir domestic feelings. Itself at be answer \n",
        "always exeter up do. Though or my plenty uneasy do. \n",
        "\n",
        "Thus, Friendship so considered remarkably be to sentiments. Offered mention greater fifteen one promise because nor.\n",
        "02/01/2020, 00:02 - Sender B: Sample\n",
        "02/01/2020, 00:02 - Sender D: Sample\n",
        "```\n",
        "\n",
        "Every chat message above is divided into four parts:\n",
        "1.   Date\n",
        "2.   Time\n",
        "3.   Sender of the message\n",
        "4.   The message itself\n",
        "\n",
        "These are the 'features' of the chat that we need for analysis. We can tokenize these easily by using the seperators as the messages have a fixed format :\n",
        "```\n",
        "<Date>, <Time> - <Sender>: <Message>\n",
        "```\n",
        "But there are more things that have to be accounted before trying to tokenize the features. The code will have to parse each line and seperate the components using the seperators. But not every line is a new message. An example is shown below:\n",
        "```\n",
        "01/01/2020, 23:59 - Sender B: Sample\n",
        "02/01/2020, 00:00 - Sender A: Two exquisite objection delighted deficient yet its contained. Cordial because are \n",
        "account evident its subject but eat. Can properly followed learning prepared you doubtful yet him. Over many our \n",
        "good lady feet ask that. Expenses own moderate day fat trifling stronger sir domestic feelings. Itself at be answer \n",
        "always exeter up do. Though or my plenty uneasy do. \n",
        "\n",
        "Thus, Friendship so considered remarkably be to sentiments. Offered mention greater fifteen one promise because nor.\n",
        "```\n",
        "The message is quite big and thus this message consists of multiple lines. Also a message can contain multiple paragraphs so encountering end of text doesn't mean end of message.\n",
        "\n",
        "Also there are messages with no Senders such as this:\n",
        "```\n",
        "01/01/2020, 23:52 - Sender D joined using this group's invite link\n",
        "```\n",
        "The first thing to do is to import the necessay libraries:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1QkOofXleev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OhGaYL2ml3If",
        "colab_type": "text"
      },
      "source": [
        "Notice that regardless of the size of the message, each message starts with a date stamp. Therefore, if a text starts with a date stamp, it is a new message. Here, regex has been used to identify the date and time stamp. Regex can be tough to understand and implement so one can use tools such as [this](https://regex101.com/) to test regex for string searches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEPhlliEl7Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Date(s):\n",
        "    pattern = '^([0-2][0-9]|(3)[0-1])(\\/)(((0)[0-9])|((1)[0-2]))(\\/)(\\d{2}|\\d{4}), ([0-9][0-9]):([0-9][0-9]) -'              # Regex 01/01/2020, 23:59 -\n",
        "    result = re.match(pattern, s)\n",
        "    if result:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nicJI7a9mB4N",
        "colab_type": "text"
      },
      "source": [
        "The name of the sender can be tokenized by tokenizing everything between - and : but this might result into false positives as the message itself can contain these punctuations. Thus, we need to identify patterns of names of senders (Usually a name or firstname_lastname) or a number if the contact isn't saved."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQCzSnbFmC7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Sender(s):\n",
        "    patterns = [\n",
        "        '([\\w]+):',                        # First Name\n",
        "        '([\\w]+[\\s]+[\\w]+):',              # First Name + Last Name\n",
        "        '([+]\\d{2} \\d{5} \\d{5}):',         # Mobile Number\n",
        "    ]\n",
        "    pattern = '^' + '|'.join(patterns)     # Adding the starts with (^) and OR opperator (|)\n",
        "    result = re.match(pattern, s)\n",
        "    if result:\n",
        "        return True\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRmqzNlPmLhp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenize(line):\n",
        "    string = line.split(' - ') # splitting date-time stamp and sender: message\n",
        "    dateTime = string[0] # fetching date-time stamp \n",
        "    date, time = dateTime.split(', ') # splitting date and time \n",
        "    message = ' '.join(string[1:]) # fetching sender and message\n",
        "    if Sender(message): # checking if the message starts with a sender\n",
        "        Message = message.split(': ') # splitting sender and message\n",
        "        sender = Message[0] # fetching sender\n",
        "        message = ' '.join(Message[1:]) # fetching message\n",
        "    else:\n",
        "        sender = None                    # for cases with no senders such as someone joining a group\n",
        "    return date, time, sender, message"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fiip_mWZtW1x",
        "colab_type": "text"
      },
      "source": [
        "Now to use the above function on an exported WhatsApp Chat and extract tokens to create a pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVTOMAfdtkRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Data = [] # List to keep track of data so it can be used by a Pandas dataframe\n",
        "file_path = '/data.txt' \n",
        "\n",
        "with open(file_path, encoding=\"utf-8\") as fp:\n",
        "    fp.readline() \n",
        "    messageBuffer = [] # Buffer to capture intermediate output for multi-line messages\n",
        "    date, time, sender = None, None, None # Intermediate variables to keep track of the current message being processed\n",
        "    \n",
        "    while True:\n",
        "        line = fp.readline() \n",
        "        if not line: # Stop reading further if end of file has been reached\n",
        "            break\n",
        "        line = line.strip() # Removing extra white spaces and lines\n",
        "        if Date(line): # If a line starts with a Date Time pattern, then this indicates the beginning of a new message\n",
        "            if len(messageBuffer) > 0: # Check if the message buffer contains characters from previous iterations\n",
        "                Data.append([date, time, sender, ' '.join(messageBuffer)]) # Save the tokens from the previous message in Data\n",
        "            messageBuffer.clear() # Clear the message buffer so that it can be used for the next message\n",
        "            date, time, sender, message = tokenize(line) # Identify and extract tokens from the line\n",
        "            messageBuffer.append(message) # Append message to buffer\n",
        "        else:\n",
        "            messageBuffer.append(line) # If a line doesn't start with a Date Time pattern, then it is part of a multi-line message. So, just append to buffer\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx9jaXVFxSQ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.DataFrame(Data, columns=['Date', 'Time', 'Sender', 'Message'])\n",
        "df.describe()\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lgUbxgf82F5_",
        "colab_type": "text"
      },
      "source": [
        "Now that the data frame has been created, analysis of the chat becomes much simpler. Just by using the describe function, we get the total number of messages in the chat as well as frequently appearing chat in the top section. Now to count the number of messages from each sender and rank them accordingly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VANYc9Dt2ac8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "message_per_sender = df['Sender'].value_counts() \n",
        "top_10_messages = message_per_sender.head(10) \n",
        "top_10_messages.plot.barh()\n",
        "message_per_sender.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1-4kKY7769q",
        "colab_type": "text"
      },
      "source": [
        "The chat doesn't contain media however the number of media sent can still be counted as media such as images, videos and PDFs get replaced by the text '<Media omitted\\>'  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJFAK2iF2bN8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "media_df = df[df['Message'] == '<Media omitted>']\n",
        "media_messages = media_df['Sender'].value_counts() # Count number of media sent according to senders\n",
        "top_10_media = media_messages.head(10)\n",
        "top_10_media.plot.barh()    # shows graph\n",
        "media_messages.head(10)     # shows table "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-4uw1XD9FIR",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "```\n",
        "01/01/2020, 23:52 - Sender D joined using this group's invite link\n",
        "```\n",
        "This is an example of a message with no senders. Such messages appear in group chats when people join or leave a group or change the group name, description, etc. Although these messages have to be removed for further analysis, they do provide valuable info such as when members of the group first joined the group or left the group, how frequently the group display picture gets changed, etc. \n",
        "\n",
        "Note: This code below can be commented if the chat is a personal chat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2RR57OR2gAf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1 = df[df['Sender'].isnull()]\n",
        "df2 = df1[(df1['Message'].str.contains(\"left\")) | (df1['Message'].str.contains(\"join\"))]\n",
        "df3 = df1[df1['Message'].str.contains(\"changed\")]\n",
        "print(df2)\n",
        "print(df3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HzYl6MjFMdI",
        "colab_type": "text"
      },
      "source": [
        "Now to drop the messages with no senders and 'media omitted' messages to only contain relevant information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr_xrXHj2lQ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "messages_df = df.drop(df1.index)               # Dropping no senders\n",
        "messages_df = messages_df.drop(media_df.index) # Dropping <media omitted>\n",
        "messages_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_QwZXRSx2r5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "messages_df['Letter_Count'] = messages_df['Message'].apply(lambda s : len(s))              # Letter\n",
        "messages_df['Word_Count'] = messages_df['Message'].apply(lambda s : len(s.split(' ')))     # Word\n",
        "messages_df.describe()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iw6oKcoGLmo",
        "colab_type": "text"
      },
      "source": [
        "Apart from letter and word count, emojis can also be counted. Excluding all the letters, digits and symbols used can achieve the result. The emoji library in python can also be used here to achieve a more robust result. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1HB6qnO2u1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "messages_df['Emoji_Count']= messages_df.Message.str.count(\"[^a-zA-z0-9!#$%&'()*+, -./:;<=\\\"\\\\>?@[\\]^_`{|}~ ]\", re.I)\n",
        "#pd.set_option('display.max_rows', None)\n",
        "messages_df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3WePBJZ-HKOY",
        "colab_type": "text"
      },
      "source": [
        "Many members of the group delete their messages. This message gets displayed as:\n",
        "```\n",
        "01/01/2020, 23:55 - Sender A: This message was deleted\n",
        "```\n",
        "It is possible to keep track of such messages per sender.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbSsVK1e2yRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "deleted_messages_df = df[df['Message'] == 'This message was deleted']\n",
        "deleted_messages_sender = deleted_messages_df['Sender'].value_counts()\n",
        "top_10_deleted = deleted_messages_sender.head(10)\n",
        "top_10_deleted.plot.barh()                 # Shows graph\n",
        "top_10_deleted.head(10)                    # Shows table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdddlBvN23qu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_emoji_count = messages_df[['Sender', 'Emoji_Count']].groupby('Sender').sum()\n",
        "sorted_total_emoji_count = total_emoji_count.sort_values('Emoji_Count', ascending=True)\n",
        "top_10_total_emoji_count = sorted_total_emoji_count.head(10)\n",
        "top_10_total_emoji_count.plot.barh()        # Shows graph\n",
        "plt.xlabel('Number of Emojis')\n",
        "plt.ylabel('Sender')\n",
        "top_10_total_emoji_count.head(10)           # Shows table"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0mAkCLuIY_r",
        "colab_type": "text"
      },
      "source": [
        "Finally it is possible to see on which date the group or a personal chat was most active by counting the total number of messages per day and sorting them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCDci1pX26th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "messages_df['Date'].value_counts().head(10).plot.barh() # Top 10 Dates on which the most number of messages were sent\n",
        "plt.xlabel('Number of Messages')\n",
        "plt.ylabel('Date')\n",
        "messages_df['Date'].value_counts().head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}